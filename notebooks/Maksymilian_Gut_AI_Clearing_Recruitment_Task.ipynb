{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wC79JBvKCrts",
        "outputId": "0b1e376f-1d5b-4286-d514-a90fbe7abaac"
      },
      "outputs": [],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un5HfEpTGiDH",
        "outputId": "ec1f9792-8370-4378-9c8b-b99640bcb4a8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torchinfo import summary\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torch.utils.data import random_split, DataLoader, Dataset\n",
        "from torchvision.transforms import transforms, ToTensor"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Database preprocessing for binary classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgEaWbRVbOrN"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "train_dataset = FashionMNIST(root='./', train=True, download=True, transform=transform)\n",
        "test_dataset =  FashionMNIST(root='./', train=False, download=True, transform=transform)\n",
        "\n",
        "# Rebalancing dataset -> 18k shoes + 7 other classes x 2571 ~= 18k\n",
        "shoes, other = [], []\n",
        "\n",
        "for idx, element in enumerate(train_dataset):\n",
        "    if element[1] == 5 or element[1] == 7 or element[1] == 9:\n",
        "        shoes.append(idx)\n",
        "    else:\n",
        "        other.append(idx)\n",
        "\n",
        "shoes_data = [train_dataset[x] for x in shoes]\n",
        "\n",
        "items_dict = train_dataset.class_to_idx\n",
        "clothes = []\n",
        "for item in items_dict:\n",
        "    if items_dict[item] != 5 and items_dict[item] != 7 != 9:\n",
        "        x = [train_dataset[x] for x in other if train_dataset[x][1] == items_dict[item]][:2571] #2571 examples from each class of non shoe category.\n",
        "        clothes.extend(x)\n",
        "\n",
        "relabeled_shoe_data = []\n",
        "for data in shoes_data:\n",
        "    new_data = list(data)\n",
        "    new_data[1] = 1.0\n",
        "    relabeled_shoe_data.append(new_data)\n",
        "\n",
        "relabeled_clothes_data = []\n",
        "for data in clothes:\n",
        "    new_data = list(data)\n",
        "    new_data[1] = 0.0\n",
        "    relabeled_clothes_data.append(new_data)\n",
        "\n",
        "train_set = relabeled_shoe_data + relabeled_clothes_data\n",
        "\n",
        "# Test data\n",
        "relabeled_test_data = []\n",
        "for data in test_dataset:\n",
        "  if data[1] == 5 or data[1] == 7 or data[1] == 9:\n",
        "    new_data = list(data)\n",
        "    new_data[1] = 1.0\n",
        "    relabeled_test_data.append(new_data)\n",
        "  else:\n",
        "    new_data = list(data)\n",
        "    new_data[1] = 0.0\n",
        "    relabeled_test_data.append(new_data)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Database split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtWTy0VS-wY_"
      },
      "outputs": [],
      "source": [
        "# Creating Datasets\n",
        "SPLIT_RATIO = 0.8\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_size = int(len(train_set)*SPLIT_RATIO)\n",
        "val_size = int(len(train_set) - train_size)\n",
        "\n",
        "\n",
        "\n",
        "train, validation = random_split(dataset = train_set,\n",
        "                          lengths = [train_size, val_size],\n",
        "                          generator = torch.Generator().manual_seed(77))\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_dataloader = DataLoader(dataset=validation, batch_size=BATCH_SIZE, shuffle = False, num_workers=2)\n",
        "test_dataloader = DataLoader(dataset=relabeled_test_data, batch_size=BATCH_SIZE, shuffle = False, num_workers=2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing training dataset and assigned label correnctness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "SCXAnaoaCa_1",
        "outputId": "f9b2cb78-6728-4b20-e38a-98f2376af5a0"
      },
      "outputs": [],
      "source": [
        "# Just checking train/val label correctness\n",
        "dataiter = iter(train_dataloader)\n",
        "print(dataiter)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "fig = plt.figure(figsize=(15,5))\n",
        "for idx in np.arange(30):\n",
        "  ax = fig.add_subplot(3, 10, idx+1, xticks=[], yticks=[])\n",
        "  ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
        "  ax.set_title(labels[idx].item())\n",
        "  fig.tight_layout()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Same as above, just for a testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "Q8ipuzrGCca_",
        "outputId": "9cf821d0-e1aa-4b8b-d889-40ebf958792a"
      },
      "outputs": [],
      "source": [
        "# Just checking test label correctness\n",
        "dataiter = iter(test_dataloader)\n",
        "print(dataiter)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "fig = plt.figure(figsize=(15,5))\n",
        "for idx in np.arange(30):\n",
        "  ax = fig.add_subplot(3, 10, idx+1, xticks=[], yticks=[])\n",
        "  ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
        "  ax.set_title(labels[idx].item())\n",
        "  fig.tight_layout()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Accuracy function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WP_7jtIjC6C6"
      },
      "outputs": [],
      "source": [
        "# Accuracy function\n",
        "def calculate_accuracy(outputs, labels):\n",
        "    predictions = torch.round(torch.sigmoid(outputs))\n",
        "    correct = (predictions == labels).sum().item()\n",
        "    total = labels.size(0)\n",
        "    accuracy = correct / total\n",
        "    return accuracy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Neural Net model class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlH0tkeRC8W7"
      },
      "outputs": [],
      "source": [
        "class BinaryFMnist(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BinaryFMnist, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "\n",
        "        self.relu = nn.LeakyReLU()\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.linear1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
        "        self.linear2 = nn.Linear(in_features=120, out_features=60)\n",
        "        self.out = nn.Linear(in_features=60, out_features=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # conv 1\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = nn.functional.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        # conv 2\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = nn.functional.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        # fc1\n",
        "        x = self.flatten(x)\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        # fc2\n",
        "        x = self.linear2(x)\n",
        "        x = self.relu(x)\n",
        "        # output\n",
        "        x = self.out(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b7QdvDPC-ot",
        "outputId": "ad204e6d-88b6-437e-d1a9-eb4b3a8290f6"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 100\n",
        "LEARNNING_RATE = 0.00001\n",
        "\n",
        "model = BinaryFMnist().to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNNING_RATE)\n",
        "\n",
        "# Train & validate\n",
        "epoch_loss, val_epoch_loss, val_epoch_accuracy = [], [], []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    #Train\n",
        "    for img, label in tqdm(train_dataloader, leave=True, desc=f'Epoch:{epoch+1}/{EPOCHS}'):\n",
        "        img, label = img.to(device), label.to(device)\n",
        "        output = model(img)\n",
        "        output = output.squeeze()\n",
        "        loss = criterion(output, label)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    epoch_loss.append(running_loss)\n",
        "\n",
        "    #Validate\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_running_loss = 0.0\n",
        "        val_running_accuracy = 0.0\n",
        "\n",
        "        for v_img, v_label in val_dataloader:\n",
        "            v_img, v_label = v_img.to(device), v_label.to(device)\n",
        "            output = model(v_img)\n",
        "            output = output.squeeze()\n",
        "            val_loss = criterion(output, v_label)\n",
        "            val_running_loss += val_loss.item()\n",
        "\n",
        "            val_accuracy = calculate_accuracy(output, v_label)\n",
        "            val_running_accuracy += val_accuracy\n",
        "\n",
        "        val_epoch_loss.append(val_running_loss)\n",
        "        val_epoch_accuracy.append(val_running_accuracy / len(val_dataloader))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train & validation loss plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "H4OBWepcDB2C",
        "outputId": "7c6b4675-cc53-4749-d2ce-72a64ff26d7b"
      },
      "outputs": [],
      "source": [
        "print(\"Training loss: \", sum(epoch_loss)/len(epoch_loss))\n",
        "print(\"Validation loss: \", sum(val_epoch_loss)/len(val_epoch_loss))\n",
        "print(\"Validation accuracy: \", sum(val_epoch_accuracy)*100/len(val_epoch_accuracy))\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(epoch_loss, label='Training')\n",
        "ax.plot(val_epoch_loss, label='Validation')\n",
        "leg = ax.legend();"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "II7UuCATDDY9",
        "outputId": "21c2ab5d-ebfc-4306-a237-93df4285a791"
      },
      "outputs": [],
      "source": [
        "# TEST\n",
        "test_loss = 0.0\n",
        "test_accuracy = 0.0\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for t_img, t_label in test_dataloader:\n",
        "        t_img, t_label = t_img.to(device), t_label.to(device)\n",
        "        output = model(t_img)\n",
        "        output = output.squeeze()\n",
        "        test_loss += criterion(output, t_label).item()  # Convert labels to Long data type\n",
        "        test_accuracy += calculate_accuracy(output, t_label)\n",
        "\n",
        "test_loss /= len(test_dataloader)\n",
        "test_accuracy /= len(test_dataloader)\n",
        "\n",
        "print('Testing Loss:', test_loss)\n",
        "print(f'Testing Accuracy: {test_accuracy * 100}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvdD-t9ADElC"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), './model.pth')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Transfer Learning "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZT8cEArepMp"
      },
      "outputs": [],
      "source": [
        "class BinaryFMnist(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BinaryFMnist, self).__init__()\n",
        "       # define layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "\n",
        "        self.relu = nn.LeakyReLU()\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.linear1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
        "        self.linear2 = nn.Linear(in_features=120, out_features=60)\n",
        "        self.out = nn.Linear(in_features=60, out_features=1)\n",
        "\n",
        "    # define forward function\n",
        "    def forward(self, x):\n",
        "        # conv 1\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = nn.functional.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        # conv 2\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = nn.functional.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        # fc1\n",
        "        x = self.flatten(x)\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        # fc2\n",
        "        x = self.linear2(x)\n",
        "        x = self.relu(x)\n",
        "        # output\n",
        "        x = self.out(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Luzl-gjjDJKu",
        "outputId": "344bde28-b0ed-4c77-ac44-336dd6694e18"
      },
      "outputs": [],
      "source": [
        "model = BinaryFMnist()\n",
        "model.load_state_dict(torch.load('./model.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9R0x1BIDLqU",
        "outputId": "974046ac-15a7-4206-9d0d-c9ef6f13ae93"
      },
      "outputs": [],
      "source": [
        "print(summary(model, input_size=(128, 1, 28, 28)))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Freezeing layers and replacing with a two new one to learn new weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvETMFlZDNVg"
      },
      "outputs": [],
      "source": [
        "# Freeze all layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "#Replace 2 last FC layers\n",
        "model.linear1 = nn.Linear(192, 120)\n",
        "model.linear2 = nn.Linear(120, 60)\n",
        "model.out = nn.Linear(60, 1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading training examples - one for each category "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x35Wh-M_DOdS"
      },
      "outputs": [],
      "source": [
        "flats_train = torchvision.io.read_image('./heels_flats/train/Flats/107.png')\n",
        "heels_train = torchvision.io.read_image('./heels_flats/train/Heels/746.png')\n",
        "img = [flats_train, heels_train]\n",
        "\n",
        "transform = transforms.Compose([transforms.ConvertImageDtype(torch.float32),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "images = [transform(x) for x in img]\n",
        "label_flats, label_heels = torch.tensor(1.0), torch.tensor(0.0)\n",
        "labels = [label_flats, label_heels]\n",
        "\n",
        "class ShoeDataset(Dataset):\n",
        "    def __init__(self, imgs, label):\n",
        "        self.image = imgs\n",
        "        self.label = label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.image[idx]\n",
        "        label = self.label[idx]\n",
        "        return image, label\n",
        "\n",
        "train_dataset = ShoeDataset(images, labels)\n",
        "transfer_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading testing examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOVgII-jDPZM"
      },
      "outputs": [],
      "source": [
        "flats_test = [torchvision.io.read_image(os.path.join('./heels_flats/test/Flats', img_dir)) for img_dir in os.listdir('./heels_flats/test/Flats')]\n",
        "heels_test = [torchvision.io.read_image(os.path.join('./heels_flats/test/Heels', img_dir)) for img_dir in os.listdir('./heels_flats/test/Heels')]\n",
        "\n",
        "transform = transforms.Compose([transforms.ConvertImageDtype(torch.float32),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "flats_images = [transform(x) for x in flats_test]\n",
        "heels_images = [transform(x) for x in heels_test]\n",
        "\n",
        "flats_labels = [torch.tensor(1.0) for x in range(len(flats_images))]\n",
        "heels_labels = [torch.tensor(0.0) for x in range(len(heels_images))]\n",
        "\n",
        "images = flats_images + heels_images\n",
        "labels = flats_labels + heels_labels\n",
        "\n",
        "class TestShoeDataset(Dataset):\n",
        "    def __init__(self, imgs, label):\n",
        "        self.image = imgs\n",
        "        self.label = label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.image[idx]\n",
        "        label = self.label[idx]\n",
        "        return image, label\n",
        "\n",
        "test_dataset = TestShoeDataset(images, labels)\n",
        "transfer_test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Retrainging new layers for new objective"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XZcPXQemDQXm",
        "outputId": "25bccbeb-ddae-4e18-8150-77a0a7cb1fe2"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "LEARNNING_RATE = 0.001\n",
        "# m c o\n",
        "model = model.to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNNING_RATE)\n",
        "\n",
        "#TRAIN\n",
        "epoch_loss = []\n",
        "for epoch in range(EPOCHS):\n",
        "    running_loss = 0.0\n",
        "    for img, label in tqdm(transfer_dataloader, leave=True, desc=f'Epoch:{epoch}/{EPOCHS}'):\n",
        "        img, label = img.to(device), label.to(device)\n",
        "\n",
        "        output = model(img)\n",
        "        output = output[0]\n",
        "\n",
        "        loss = criterion(output, label)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    epoch_loss.append(running_loss)\n",
        "\n",
        "plt.plot(epoch_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehxpIqtdDRcy",
        "outputId": "4d208c62-2ba1-4ec2-8cf5-4113802cd5f9"
      },
      "outputs": [],
      "source": [
        "# TEST\n",
        "test_loss = 0.0\n",
        "test_accuracy = 0.0\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for t_img, t_label in transfer_test_dataloader:\n",
        "        t_img, t_label = t_img.to(device), t_label.to(device)\n",
        "        output = model(t_img)\n",
        "        output = output[0]\n",
        "        test_loss += criterion(output, t_label).item()  # Convert labels to Long data type\n",
        "        test_accuracy += calculate_accuracy(output, t_label)\n",
        "\n",
        "test_loss /= len(transfer_test_dataloader)\n",
        "test_accuracy /= len(transfer_test_dataloader)\n",
        "\n",
        "print('Testing Loss:', test_loss)\n",
        "print(f'Testing Accuracy: {test_accuracy * 100}%')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
